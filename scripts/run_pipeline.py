import os
import sys
import argparse
import logging
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from pathlib import Path
import multiprocessing
from torch.utils.data import DataLoader
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.data_processing import load_and_preprocess_data, get_augmented_dataset
from models.cnn_model import create_model
from utils.training import (
    train_model, evaluate_model, EarlyStopping, visualize_training_history,
    visualize_predictions, visualize_error_distribution, CombinedLoss, HuberCorrelationLoss,
    FocalCorrelationLoss, AdaptiveCorrelationLoss
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def set_seed(seed=42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æžœå¯é‡çŽ°"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    # è®¾ç½®ç¡®å®šæ€§ç®—æ³•
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    logger.info(f"éšæœºç§å­å·²è®¾ç½®ä¸º {seed}")

def optimize_cpu_performance():
    """ä¼˜åŒ–CPUæ€§èƒ½è®¾ç½®"""
    # è®¾ç½®çº¿ç¨‹æ•°ä¸ºç‰©ç†æ ¸å¿ƒæ•°
    num_cores = multiprocessing.cpu_count()
    torch.set_num_threads(num_cores)
    
    # å¯ç”¨PyTorchçš„å†…éƒ¨ä¼˜åŒ–
    torch.set_float32_matmul_precision('high')
    
    # å¯ç”¨Intel MKLä¼˜åŒ– (å¦‚æžœå¯ç”¨)
    if hasattr(torch, 'backends') and hasattr(torch.backends, 'mkldnn'):
        torch.backends.mkldnn.enabled = True
    
    # å¯ç”¨å†…å­˜é’‰æ‰Žï¼Œå‡å°‘å†…å­˜å¤åˆ¶å¼€é”€
    torch.backends.cuda.matmul.allow_tf32 = True
    
    # è®¾ç½®è¾ƒå¤§çš„æ‰¹å¤„ç†å¤§å°ä»¥æé«˜åžåé‡
    # å¯ç”¨å¼‚æ­¥æ•°æ®åŠ è½½å’Œé¢„å–
    torch.multiprocessing.set_sharing_strategy('file_system')
    
    logger.info(f"CPUæ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨: ä½¿ç”¨ {num_cores} ä¸ªçº¿ç¨‹")

def train_and_evaluate(args):
    """è¿è¡Œæ•´ä¸ªè®­ç»ƒå’Œè¯„ä¼°æµç¨‹"""
    # ä¼˜åŒ–CPUæ€§èƒ½
    optimize_cpu_performance()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    logger.info(f"åŠ è½½å’Œé¢„å¤„ç† {args.function} æ•°æ®é›†")
    train_dataset, val_dataset, test_dataset, feature_scaler, target_scaler = load_and_preprocess_data(
        function_name=args.function,
        log_transform=False  # é»˜è®¤ä¸ä½¿ç”¨å¯¹æ•°å˜æ¢ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨MSEæŸå¤±
    )
    
    # åº”ç”¨æ•°æ®å¢žå¼ºï¼ˆå¦‚æžœå¯ç”¨ï¼‰
    if args.data_augmentation:
        logger.info("åº”ç”¨æ•°æ®å¢žå¼º...")
        augmented_dataset = get_augmented_dataset(train_dataset, augmentation_factor=0.5)
        # åˆ›å»ºæ–°çš„æ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            augmented_dataset, 
            batch_size=args.batch_size, 
            shuffle=True, 
            num_workers=0,  # ä½¿ç”¨å•è¿›ç¨‹æ•°æ®åŠ è½½
            pin_memory=True  # å¯ç”¨å†…å­˜é’‰æ‰Ž
        )
        logger.info(f"æ•°æ®å¢žå¼ºåŽçš„è®­ç»ƒé›†å¤§å°: {len(augmented_dataset)}")
    else:
        # ä¸ä½¿ç”¨æ•°æ®å¢žå¼ºï¼Œç›´æŽ¥ä½¿ç”¨åŽŸå§‹æ•°æ®é›†
        train_loader = DataLoader(
            train_dataset, 
            batch_size=args.batch_size, 
            shuffle=True,
            num_workers=0,  # ä½¿ç”¨å•è¿›ç¨‹æ•°æ®åŠ è½½
            pin_memory=True
        )
    
    # åˆ›å»ºéªŒè¯é›†å’Œæµ‹è¯•é›†çš„æ•°æ®åŠ è½½å™¨
    val_loader = DataLoader(
        val_dataset, 
        batch_size=args.batch_size * 2,  # éªŒè¯æ—¶å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡
        shuffle=False,
        num_workers=0,  # ä½¿ç”¨å•è¿›ç¨‹æ•°æ®åŠ è½½
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=args.batch_size * 2,  # æµ‹è¯•æ—¶å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡
        shuffle=False,
        num_workers=0,  # ä½¿ç”¨å•è¿›ç¨‹æ•°æ®åŠ è½½
        pin_memory=True
    )
    
    # åˆ›å»ºæ¨¡åž‹
    logger.info(f"åˆ›å»º {args.model_type} CNNæ¨¡åž‹")
    model = create_model(model_type=args.model_type, dropout_rate=args.dropout_rate)
    
    # è®¾ç½®è®¾å¤‡(CPU/GPU)
    device = torch.device('cuda' if torch.cuda.is_available() and not args.no_cuda else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # é€‰æ‹©æŸå¤±å‡½æ•° - é»˜è®¤ä½¿ç”¨MSE
    criterion = nn.MSELoss()
    logger.info(f"ä½¿ç”¨æŸå¤±å‡½æ•°: MSE")
    
    # é€‰æ‹©ä¼˜åŒ–å™¨
    if args.optimizer == 'adam':
        optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
    elif args.optimizer == 'sgd':
        optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=args.weight_decay)
    elif args.optimizer == 'adamw':
        optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨ç±»åž‹: {args.optimizer}")
    
    logger.info(f"ä½¿ç”¨ä¼˜åŒ–å™¨: {optimizer.__class__.__name__}, å­¦ä¹ çŽ‡: {args.learning_rate}")
    
    # é€‰æ‹©å­¦ä¹ çŽ‡è°ƒåº¦å™¨
    if args.scheduler == 'step':
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)
    elif args.scheduler == 'cosine':
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epochs)
    elif args.scheduler == 'reduce_on_plateau':
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.gamma, 
                                                       patience=args.lr_patience, verbose=True)
    elif args.scheduler == 'warmup_cosine':
        from torch.optim.lr_scheduler import CosineAnnealingLR
        from torch.optim.lr_scheduler import LinearLR
        from torch.optim.lr_scheduler import SequentialLR
        
        # åˆ›å»ºé¢„çƒ­è°ƒåº¦å™¨
        warmup_scheduler = LinearLR(
            optimizer, 
            start_factor=0.1, 
            end_factor=1.0, 
            total_iters=int(args.num_epochs * 0.1)  # é¢„çƒ­10%çš„è½®æ¬¡
        )
        
        # åˆ›å»ºä½™å¼¦é€€ç«è°ƒåº¦å™¨
        cosine_scheduler = CosineAnnealingLR(
            optimizer, 
            T_max=int(args.num_epochs * 0.9),  # ä½™ä¸‹90%çš„è½®æ¬¡
            eta_min=args.learning_rate * 0.01  # æœ€å°å­¦ä¹ çŽ‡ä¸ºåˆå§‹å­¦ä¹ çŽ‡çš„1%
        )
        
        # ç»„åˆä¸¤ä¸ªè°ƒåº¦å™¨
        scheduler = SequentialLR(
            optimizer,
            schedulers=[warmup_scheduler, cosine_scheduler],
            milestones=[int(args.num_epochs * 0.1)]  # åœ¨10%çš„è½®æ¬¡å¤„åˆ‡æ¢
        )
    else:
        scheduler = None
    
    if scheduler is not None:
        logger.info(f"ä½¿ç”¨å­¦ä¹ çŽ‡è°ƒåº¦å™¨: {scheduler.__class__.__name__}")
    
    # è®¾ç½®æ—©åœ
    early_stopping = None
    if args.early_stopping:
        early_stopping = EarlyStopping(patience=args.patience, verbose=True)
        logger.info(f"å¯ç”¨æ—©åœï¼Œè€å¿ƒå€¼: {args.patience}")
    
    # è®­ç»ƒæ¨¡åž‹
    logger.info(f"å¼€å§‹è®­ç»ƒæ¨¡åž‹ï¼Œæœ€å¤§è½®æ¬¡: {args.num_epochs}")
    history = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        device=device,
        num_epochs=args.num_epochs,
        scheduler=scheduler,
        early_stopping=early_stopping,
        model_save_path=os.path.join(args.output_dir, f"{args.function}_{args.model_type}_model.pth"),
        log_interval=args.log_interval
    )
    
    # å¯è§†åŒ–è®­ç»ƒåŽ†å²
    visualize_training_history(
        history, 
        save_path=os.path.join(args.output_dir, f"{args.function}_{args.model_type}_history.png")
    )
    
    # åŠ è½½æœ€ä½³æ¨¡åž‹
    best_model_path = os.path.join(args.output_dir, f"{args.function}_{args.model_type}_model.pth")
    model.load_state_dict(torch.load(best_model_path, weights_only=True))
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡åž‹
    logger.info("åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡åž‹...")
    test_results = evaluate_model(model, test_loader, criterion, device)
    test_loss = test_results['loss']
    test_pearson = test_results['pearson']
    logger.info(f"æµ‹è¯•é›†ç»“æžœ - æŸå¤±: {test_loss:.6f}, Pearsonç›¸å…³ç³»æ•°: {test_pearson:.6f}")
    
    # å¯è§†åŒ–é¢„æµ‹ç»“æžœ
    visualize_predictions(
        model, 
        test_loader, 
        device, 
        save_path=os.path.join(args.output_dir, f"{args.function}_{args.model_type}_predictions.png")
    )
    
    # å¯è§†åŒ–è¯¯å·®åˆ†å¸ƒ
    visualize_error_distribution(
        model, 
        test_loader, 
        device, 
        save_path=os.path.join(args.output_dir, f"{args.function}_{args.model_type}_errors.png")
    )
    
    # ä¿å­˜ç»“æžœåˆ°æ–‡æœ¬æ–‡ä»¶
    results_path = os.path.join(args.output_dir, f"{args.function}_{args.model_type}_results.txt")
    with open(results_path, 'w') as f:
        f.write(f"æ¨¡åž‹ç±»åž‹: {args.model_type}\n")
        f.write(f"å‡½æ•°: {args.function}\n")
        f.write(f"æ‰¹é‡å¤§å°: {args.batch_size}\n")
        f.write(f"å­¦ä¹ çŽ‡: {args.learning_rate}\n")
        f.write(f"æƒé‡è¡°å‡: {args.weight_decay}\n")
        f.write(f"ä¼˜åŒ–å™¨: {args.optimizer}\n")
        f.write(f"æŸå¤±å‡½æ•°: {args.loss_type}\n")
        f.write(f"æ•°æ®å¢žå¼º: {args.data_augmentation}\n")
        f.write(f"DropoutçŽ‡: {args.dropout_rate}\n")
        f.write(f"æ—©åœè€å¿ƒå€¼: {args.patience if args.early_stopping else 'N/A'}\n")
        f.write(f"å­¦ä¹ çŽ‡è°ƒåº¦å™¨: {args.scheduler}\n")
        f.write(f"éšæœºç§å­: {args.seed}\n\n")
        f.write(f"æµ‹è¯•é›†æŸå¤±: {test_loss:.6f}\n")
        f.write(f"æµ‹è¯•é›†Pearsonç›¸å…³ç³»æ•°: {test_pearson:.6f}\n")
    
    logger.info(f"ç»“æžœå·²ä¿å­˜åˆ° {results_path}")
    
    return test_pearson

def main():
    parser = argparse.ArgumentParser(description='CNNæ¨¡åž‹è®­ç»ƒå’Œè¯„ä¼°')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--function', type=str, default='Rosenbrock', choices=['Ackley', 'Rosenbrock'],
                        help='è¦å­¦ä¹ çš„å‡½æ•° (é»˜è®¤: Rosenbrock)')
    parser.add_argument('--data_augmentation', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨æ•°æ®å¢žå¼º')
    parser.add_argument('--batch_size', type=int, default=64,
                        help='æ‰¹é‡å¤§å° (é»˜è®¤: 64)')
    
    # æ¨¡åž‹å‚æ•°
    parser.add_argument('--model_type', type=str, default='basic', choices=['basic', 'advanced', 'enhanced'],
                        help='CNNæ¨¡åž‹ç±»åž‹ (é»˜è®¤: basic)')
    parser.add_argument('--dropout_rate', type=float, default=0.3,
                        help='DropoutçŽ‡ (é»˜è®¤: 0.3)')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--num_epochs', type=int, default=200,
                        help='è®­ç»ƒè½®æ¬¡ (é»˜è®¤: 200)')
    parser.add_argument('--learning_rate', type=float, default=0.001,
                        help='å­¦ä¹ çŽ‡ (é»˜è®¤: 0.001)')
    parser.add_argument('--weight_decay', type=float, default=1e-6,
                        help='æƒé‡è¡°å‡ (é»˜è®¤: 1e-6)')
    parser.add_argument('--optimizer', type=str, default='adam', choices=['adam', 'sgd', 'adamw'],
                        help='ä¼˜åŒ–å™¨ç±»åž‹ (é»˜è®¤: adam)')
    parser.add_argument('--loss_type', type=str, default='mse', 
                        choices=['mse', 'huber', 'combined', 'huber_correlation', 'focal_correlation', 'adaptive_correlation'],
                        help='æŸå¤±å‡½æ•°ç±»åž‹ (é»˜è®¤: mse)')
    
    # å­¦ä¹ çŽ‡è°ƒåº¦å‚æ•°
    parser.add_argument('--scheduler', type=str, default=None, 
                        choices=['None', 'step', 'cosine', 'reduce_on_plateau', 'warmup_cosine'],
                        help='å­¦ä¹ çŽ‡è°ƒåº¦å™¨ç±»åž‹ (é»˜è®¤: None)')
    parser.add_argument('--step_size', type=int, default=30,
                        help='StepLRçš„æ­¥é•¿ (é»˜è®¤: 30)')
    parser.add_argument('--gamma', type=float, default=0.1,
                        help='å­¦ä¹ çŽ‡è¡°å‡å› å­ (é»˜è®¤: 0.1)')
    parser.add_argument('--lr_patience', type=int, default=10,
                        help='ReduceLROnPlateauçš„è€å¿ƒå€¼ (é»˜è®¤: 10)')
    
    # æ—©åœå‚æ•°
    parser.add_argument('--early_stopping', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨æ—©åœ')
    parser.add_argument('--patience', type=int, default=50,
                        help='æ—©åœè€å¿ƒå€¼ (é»˜è®¤: 50)')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--output_dir', type=str, default='results',
                        help='è¾“å‡ºç›®å½• (é»˜è®¤: results)')
    parser.add_argument('--log_interval', type=int, default=5,
                        help='æ—¥å¿—æ‰“å°é—´éš” (é»˜è®¤: æ¯5ä¸ªepoch)')
    parser.add_argument('--no_cuda', action='store_true',
                        help='ç¦ç”¨CUDA (å³ä½¿å¯ç”¨)')
    
    # ç‰¹æ®ŠæŸå¤±å‡½æ•°å‚æ•°
    parser.add_argument('--gamma_focal', type=float, default=2.0,
                        help='Focal Lossçš„gammaå‚æ•° (é»˜è®¤: 2.0)')
    parser.add_argument('--beta', type=float, default=0.6,
                        help='ç»„åˆæŸå¤±çš„betaå‚æ•° (é»˜è®¤: 0.6)')
    parser.add_argument('--adaptation_rate', type=float, default=0.01,
                        help='è‡ªé€‚åº”æŸå¤±çš„é€‚åº”çŽ‡ (é»˜è®¤: 0.01)')
    
    args = parser.parse_args()
    
    # æ‰“å°æ‰€æœ‰å‚æ•°
    logger.info("è®­ç»ƒå‚æ•°:")
    for arg in vars(args):
        logger.info(f"{arg}: {getattr(args, arg)}")
    
    # è¿è¡Œè®­ç»ƒå’Œè¯„ä¼°
    test_pearson = train_and_evaluate(args)
    
    # æ‰“å°æœ€ç»ˆç»“æžœ
    logger.info(f"æœ€ç»ˆæµ‹è¯•é›†Pearsonç›¸å…³ç³»æ•°: {test_pearson:.6f}")
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
    if test_pearson > 0.85:
        logger.info("ðŸŽ‰ æˆåŠŸè¾¾åˆ°ç›®æ ‡Pearsonç›¸å…³ç³»æ•° > 0.85!")
    else:
        logger.info(f"âŒ æœªè¾¾åˆ°ç›®æ ‡Pearsonç›¸å…³ç³»æ•° > 0.85. å®žé™…å€¼: {test_pearson:.6f}")

if __name__ == "__main__":
    main() 