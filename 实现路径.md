# CNN网络学习Ackley_train和Rosenbrock_train的实施计划

## 目标

搭建一个CNN网络学习Ackley_train和Rosenbrock_train数据集，使对应的测试集Ackley_test和Rosenbrock_test上的pearson ratio超过0.85。

## 1. 数据理解与分析

### 数学函数特性分析

- 了解Ackley函数和Rosenbrock函数的数学特性
- 分析这些函数的非线性程度和挑战性
- 识别可能影响学习难度的函数特征

#### 分析结果

##### Ackley函数特性
- 在整个搜索空间中具有许多局部最小值
- 有一个全局最小值位于原点
- 函数形状像一个带有中心洞的扁平区域
- 随着维度增加，函数会变得更加复杂和难以优化
- 数学表达式: f(x) = -20*exp(-0.2*sqrt(0.5*(x1^2+x2^2))) - exp(0.5*(cos(2*pi*x1)+cos(2*pi*x2))) + e + 20

##### Rosenbrock函数特性
- 有一个狭长的抛物线形状的山谷
- 全局最小值位于山谷内部的一点
- 找到山谷相对容易，但找到山谷中的最小值非常困难
- 常用于测试优化算法的收敛性能
- 数学表达式: f(x) = sum_{i=1}^{d-1} [100*(x_{i+1} - x_i^2)^2 + (x_i - 1)^2]

### 数据集探索

#### 数据集基本信息

##### Ackley数据集
- 训练集：X形状=(800, 20)，Y形状=(800,)
- 测试集：X形状=(200, 20)，Y形状=(200,)

##### Rosenbrock数据集
- 训练集：X形状=(800, 20)，Y形状=(800,)
- 测试集：X形状=(200, 20)，Y形状=(200,)

#### 统计分析

##### Ackley数据集统计
- 特征范围：[-5, 5]
- 目标值均值：10.49
- 目标值标准差：0.67
- 目标值范围：[7.81, 12.53]
- 数据质量：无NaN值，无Inf值

##### Rosenbrock数据集统计
- 特征范围：[-5, 5]
- 目标值均值：263,638
- 目标值标准差：84,719
- 目标值范围：[67,698, 563,158]
- 数据质量：无NaN值，无Inf值

#### 特征与目标关系
- Ackley数据集：特征与目标的线性相关性低，最大相关系数约0.034
- Rosenbrock数据集：特征与目标的线性相关性低，最大相关系数约0.083
- 两个数据集均显示出高度非线性的特征-目标关系

#### 训练集和测试集相似度

##### Ackley数据集
- 特征均值相对差异(平均)：4.30
- 特征标准差相对差异(平均)：0.02
- 目标值均值相对差异：0.0021
- 目标值标准差相对差异：0.0065

##### Rosenbrock数据集
- 特征均值相对差异(平均)：17.19
- 特征标准差相对差异(平均)：0.04
- 目标值均值相对差异：0.014
- 目标值标准差相对差异：0.069

### 可视化分析

#### 生成的可视化图表
- 特征分布图：显示各特征的分布情况
- 特征-目标关系图：展示各特征与目标值的关系
- 特征相关性矩阵：展示特征间的相关程度
- 训练集-测试集比较图：对比两个数据集的分布差异

### 主要挑战与发现

1. **数据规模有限**：两个数据集都只有800个训练样本，可能需要数据增强
2. **非线性关系**：特征与目标的线性相关性非常低，表明函数关系高度非线性
3. **高维特征空间**：20个特征维度增加了模型学习的复杂性
4. **不同量级的目标值**：Ackley目标值约为10，而Rosenbrock目标值约为263,000，量级差异大
5. **测试集与训练集分布差异**：特别是Rosenbrock数据集的特征均值差异较大(17.19)，可能影响泛化性能

## 2. 数据预处理

### 特征重塑

- 将原始20维特征(800, 20)重塑为2D形式(800, 1, 4, 5)
- 将一维特征转换为二维形式，便于使用2D CNN进行处理
- 每个样本被视为单通道的4×5特征矩阵

### 标准化处理

- 使用StandardScaler对所有特征进行标准化，使均值为0，标准差为1
- 标准化有助于加速模型收敛并提高性能
- 保存标准化参数以便在测试阶段和预测时使用

### 目标值变换
- Ackley函数：目标值范围适中(7.81~12.53)，保持原值不变
- Rosenbrock函数：目标值范围较大(67,698~563,158)，应用对数变换(log1p)
- 对数变换可降低数值量级差异，有助于模型更好地学习

### 数据增强
- 高斯噪声：向特征添加小幅随机噪声(均值0，标准差0.01)
- 随机缩放：特征值乘以随机因子(0.95~1.05)
- 合成样本生成：通过线性插值原始样本对生成新样本
- 增强因子设为0.5，使训练集扩充50%

### 数据加载器实现
- 创建自定义FunctionDataset类处理数据加载和转换
- 使用PyTorch DataLoader实现批处理(batch_size=32)
- 开启shuffle=True确保训练数据被随机打乱
- 实现__getitem__方法支持按需数据重塑和转换

### 预处理流程示例

```python
# 主要预处理步骤
x_train = StandardScaler().fit_transform(x_train)  # 标准化特征
if function_name == 'Rosenbrock':
    y_train = np.log1p(y_train)  # Rosenbrock值进行对数变换
x_train = x_train.reshape(-1, 1, 4, 5)  # 重塑为2D形式
```

## 3. 模型设计

### CNN架构设计

#### 基础版本

- 简单的1D卷积层结构
- 适当的池化层
- 基本的全连接输出层

#### 进阶版本

- 多层卷积结构
- 残差连接
- 批归一化层
- 注意力机制（可选）

### 激活函数选择

- 尝试ReLU、LeakyReLU、GELU等不同激活函数
- 分析不同激活函数对性能的影响

### 正则化策略

- 实现Dropout防止过拟合
- 添加L1/L2正则化
- 使用早停机制

## 4. 模型训练

### 损失函数选择

- 主要使用MSE（均方误差）
- 可能尝试Huber Loss处理异常值
- 考虑添加相关性损失项

### 优化器配置

- 使用Adam优化器
- 设置合适的初始学习率
- 实现权重衰减

## 5. 模型评估

### 评估指标

- 实现皮尔逊相关系数计算
- 同时监控MSE、MAE和R²指标
- 设置目标阈值（>0.85）

### 测试集验证

- 在独立测试集上评估性能
- 确保没有数据泄露
- 分析测试误差分布

### 结果可视化

- 创建预测vs实际值散点图
- 绘制学习曲线
- 可视化误差分布

## 6. 模型调优

### 超参数调整

- 批量大小优化
- 学习率调整
- 网络深度和宽度调整
- 正则化强度调整

### 架构优化

- 尝试不同的卷积核大小
- 调整网络层数和通道数
- 实验不同的池化策略
- 添加高级组件（残差块等）

### 高级技术

- 实现模型集成
- 尝试迁移学习（如适用）
- 考虑自适应优化技术

## 7. 结果分析与总结

### 性能分析

- 比较不同模型架构的性能
- 分析最佳模型的特点
- 定量评估达成目标的程度

### 难点突破

- 总结遇到的挑战
- 分析解决方案有效性
- 记录关键突破点

### 经验总结

- 提炼成功经验
- 总结设计决策
- 提出潜在改进方向

## 项目文件结构使用

- `utils/data_processing.py`: 数据预处理和加载
- `models/advanced_cnn_model.py`: CNN模型实现
- `analysis/hyperparameter_tuning.py`: 超参数调优
- `models/compare_models.py`: 模型比较和评估
- `scripts/run_pipeline.py`: 执行整个训练流程
- `analysis/model_visualization.py`: 可视化模型结构和结果
- `analysis/model_explanation.py`: 模型解释和分析

## 预期结果
成功构建的CNN模型应能在Ackley和Rosenbrock测试数据集上达到超过0.85的皮尔逊相关系数，表明模型能够有效学习这些复杂非线性函数的特性并做出准确预测。

## 8. 成功因素与经验总结

### 评估指标优化的成功因素

1. **归一化MSE的引入**
   - 解决了不同函数输出值尺度差异的问题
   - 使Rosenbrock和Ackley函数的性能可以直接比较
   - 计算方法：normalized_mse = mse / (target_range ** 2)

2. **目标值范围的考虑**
   - Rosenbrock函数：
     - 目标值范围：89039.90 - 475321.91
     - 原始MSE：915,819,392.0000
     - 归一化MSE：0.006138
     - R²：0.8529
   - Ackley函数：
     - 目标值范围：8.55 - 11.98
     - 原始MSE：0.2692
     - 归一化MSE：0.022961
     - R²：0.3914

3. **评估指标的完整性**
   - 同时考虑多个评估指标：
     - 皮尔逊相关系数
     - 原始MSE和归一化MSE
     - RMSE和MAE
     - R²值
   - 提供了全面的模型性能评估视角

4. **数据记录的规范化**
   - 统一的结果文件格式
   - 完整的训练配置记录
   - 清晰的日志输出

### 模型架构优化

1. **基础CNN模型结构**
   - 两层卷积层配合批归一化
   - 适当的池化层减少参数量
   - 全连接层设计合理(640→64→1)
   - 使用批归一化加速训练并提高稳定性
   - 适当的Dropout率(0.3)有效防止过拟合

2. **训练参数优化**
   - 批量大小增加到64，提高训练效率
   - 学习率设置为0.001，平衡收敛速度和稳定性
   - 权重衰减(1e-6)提供适当的正则化
   - 早停策略(patience=50)防止过拟合

3. **数据处理策略**
   - 特征标准化对模型训练至关重要
   - 将一维特征(20)重塑为二维形式(1,4,5)，便于CNN处理
   - 不对Rosenbrock函数的目标值进行对数变换，保留原始分布特性

4. **CPU性能优化**
   - 设置合适的线程数量
   - 启用内存固定(pin_memory)和异步数据加载
   - 优化工作线程数量，避免过多线程导致的开销

### 经验教训与最佳实践

1. **简单模型优先**
   - 基础CNN模型比复杂的增强型模型表现更好
   - 复杂的注意力机制和残差连接可能引入不必要的复杂性

2. **损失函数的重要性**
   - 选择合适的损失函数对模型性能影响显著
   - MSE损失函数对回归问题更为适合

3. **批量大小的影响**
   - 增加批量大小从32到64显著提高了训练效率
   - 较大的批量大小提供更稳定的梯度估计

4. **数据预处理的关键作用**
   - 特征标准化是提高模型性能的关键步骤
   - 特征重塑为二维形式使CNN能够有效学习空间特征

5. **评估指标的全面性**
   - 综合考虑多个评估指标提供更全面的性能评估
   - 定期评估有助于及时发现过拟合问题

### 未来改进方向

1. **模型轻量化**

   - 进一步优化模型结构，减少参数量
   - 探索量化和剪枝技术，减小模型体积

2. **迁移学习探索**

   - 研究Rosenbrock模型知识迁移到Ackley函数
   - 探索不同函数之间的共性特征

3. **集成学习尝试**

   - 尝试多个基础模型的集成
   - 探索不同集成策略(平均、加权、堆叠等)

4. **自动化超参数优化**

   - 实现系统的超参数搜索
   - 自动化模型选择和评估流程 